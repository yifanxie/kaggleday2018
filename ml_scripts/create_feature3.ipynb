{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from project_utils import kd_utils\n",
    "from importlib import reload\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv', sep='\\t')\n",
    "test=pd.read_csv('../input/test.csv', sep='\\t')\n",
    "\n",
    "train['question_dt']=pd.to_datetime(train['question_utc'], unit='s')\n",
    "test['question_dt']=pd.to_datetime(test['question_utc'], unit='s')\n",
    "train['answer_dt']=pd.to_datetime(train['answer_utc'], unit='s')\n",
    "test['answer_dt']=pd.to_datetime(test['answer_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['answer_score']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest=train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittext(x):\n",
    "    return x.replace('.', ' ').replace(',', ' ').replace(':', ' ').replace(';', ' ').replace('#', ' ').replace('!',\n",
    "                                                                                                               ' ').split(\n",
    "        ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest['qlenchar'] = traintest.question_text.apply(len)\n",
    "traintest['qlenword'] = traintest.question_text.apply(lambda x: len(splittext(x)))\n",
    "traintest['alenchar'] = traintest.answer_text.apply(len)\n",
    "traintest['alenword'] = traintest.answer_text.apply(lambda x: len(splittext(x)))\n",
    "\n",
    "traintest['difflenchar'] = traintest.qlenchar - traintest.alenchar\n",
    "traintest['difflenword'] = traintest.qlenword - traintest.alenword\n",
    "\n",
    "traintest['divlenchar'] = traintest.qlenchar / traintest.alenchar\n",
    "traintest['divlenword'] = traintest.qlenword / traintest.alenword\n",
    "\n",
    "traintest['idivlenchar'] = traintest.alenchar / traintest.qlenchar\n",
    "traintest['idivlenword'] = traintest.alenword / traintest.qlenword\n",
    "\n",
    "traintest['subreddit_le'] = LabelEncoder().fit_transform(traintest.subreddit)\n",
    "traintest['qid'] = LabelEncoder().fit_transform(traintest.question_id)\n",
    "\n",
    "# traintest['qdt_dow'] = pd.to_datetime(traintest.question_utc, origin='unix', unit='s').dt.dayofweek\n",
    "# traintest['qdt_hour'] = pd.to_datetime(traintest.question_utc, origin='unix', unit='s').dt.hour\n",
    "\n",
    "# traintest['adt_dow'] = pd.to_datetime(traintest.answer_utc, origin='unix', unit='s').dt.dayofweek\n",
    "# traintest['adt_hour'] = pd.to_datetime(traintest.answer_utc, origin='unix', unit='s').dt.hour\n",
    "\n",
    "traintest['question_score_l1p'] = np.log1p(traintest.question_score)\n",
    "traintest['answer_score_l1p'] = np.log1p(traintest.answer_score)\n",
    "\n",
    "traintest['qboldwords'] = traintest.question_text.apply(lambda x: np.sum(x.isupper() for x in splittext(x) if len(x) > 1))\n",
    "traintest['aboldwords'] = traintest.answer_text.apply(lambda x: np.sum(x.isupper() for x in splittext(x) if len(x) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ! 179762 180502\n",
      "1 ;-) 190 301\n",
      "2 :-) 452 685\n",
      "3 :-( 206 182\n",
      "4 fuck 107719 69318\n",
      "5 poop 2323 1404\n",
      "6 shit 86414 65498\n",
      "7 garbage 3702 2552\n",
      "8 crap 8551 5574\n",
      "9 dumb 10286 7458\n",
      "10 excellent 2292 1999\n",
      "11 brilliant 1632 1344\n",
      "12 good 102258 88697\n",
      "13 bad 51654 41034\n",
      "14 poor 15162 11509\n"
     ]
    }
   ],
   "source": [
    "traintest['acount'] = traintest.groupby('qid').id.transform(lambda x:x.count())\n",
    "\n",
    "EMO= ['!',\n",
    "     ';-)',\n",
    "    ':-)',\n",
    "    ':-(',\n",
    "    'fuck',\n",
    "    'poop',\n",
    "    'shit',\n",
    "    'garbage',\n",
    "    'crap',\n",
    "    'dumb',\n",
    "    'excellent',\n",
    "    'brilliant',\n",
    "    'good',\n",
    "    'bad',\n",
    "    'poor']\n",
    "\n",
    "for i,emo in enumerate(EMO):\n",
    "    traintest['qEMO'+str(i)] = traintest.question_text.apply(lambda x:x.lower().count(emo))\n",
    "    traintest['aEMO'+str(i)] = traintest.answer_text.apply(lambda x:x.lower().count(emo))\n",
    "    print(i,emo,traintest['qEMO'+str(i)].sum(),traintest['aEMO'+str(i)].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=traintest[0:len(train)]\n",
    "test=traintest[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['answer_dt', 'answer_score', 'answer_text', 'answer_utc', 'id',\n",
       "       'question_dt', 'question_id', 'question_score', 'question_text',\n",
       "       'question_utc', 'subreddit', 'qlenchar', 'qlenword', 'alenchar',\n",
       "       'alenword', 'difflenchar', 'difflenword', 'divlenchar', 'divlenword',\n",
       "       'idivlenchar', 'idivlenword', 'subreddit_le', 'qid',\n",
       "       'question_score_l1p', 'answer_score_l1p', 'qboldwords', 'aboldwords',\n",
       "       'acount', 'qEMO0', 'aEMO0', 'qEMO1', 'aEMO1', 'qEMO2', 'aEMO2', 'qEMO3',\n",
       "       'aEMO3', 'qEMO4', 'aEMO4', 'qEMO5', 'aEMO5', 'qEMO6', 'aEMO6', 'qEMO7',\n",
       "       'aEMO7', 'qEMO8', 'aEMO8', 'qEMO9', 'aEMO9', 'qEMO10', 'aEMO10',\n",
       "       'qEMO11', 'aEMO11', 'qEMO12', 'aEMO12', 'qEMO13', 'aEMO13', 'qEMO14',\n",
       "       'aEMO14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols=['answer_dt', 'answer_score', 'answer_text', 'answer_utc', 'id',\n",
    "       'question_dt', 'question_id', 'question_score', 'question_text',\n",
    "       'question_utc', 'subreddit','qid','answer_score_l1p']\n",
    "\n",
    "train_fs3=train.drop(dropcols, axis=1)\n",
    "test_fs3=test.drop(dropcols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_utils.pickle_data('../feature_data/train_fs3.pkl', train_fs3)\n",
    "kd_utils.pickle_data('../feature_data/test_fs3.pkl', test_fs3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
