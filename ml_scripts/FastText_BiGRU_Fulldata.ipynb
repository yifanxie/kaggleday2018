{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "np.random.seed(32)\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "import keras as ks\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, CuDNNGRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Concatenate\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D, LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "from importlib import reload\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from project_utils import kd_utils\n",
    "\n",
    "pd.options.display.float_format = '{:,.8f}'.format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682308\n",
      "170577\n"
     ]
    }
   ],
   "source": [
    "uid=kd_utils.load_data('../input/indices.pkl')\n",
    "trn_id=uid[0][0]\n",
    "val_id=uid[0][1]\n",
    "print(len(trn_id))\n",
    "print(len(val_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fs1=kd_utils.load_data('../feature_data/train_fs1.pkl')\n",
    "train_fs2=kd_utils.load_data('../feature_data/train_fs2.pkl')\n",
    "train_fs3=kd_utils.load_data('../feature_data/train_fs3.pkl')\n",
    "\n",
    "\n",
    "test_fs1=kd_utils.load_data('../feature_data/test_fs1.pkl')\n",
    "test_fs2=kd_utils.load_data('../feature_data/test_fs2.pkl')\n",
    "test_fs3=kd_utils.load_data('../feature_data/test_fs3.pkl')\n",
    "\n",
    "\n",
    "train_fs = pd.concat([train_fs1, train_fs2, train_fs3], axis=1)\n",
    "test_fs = pd.concat([test_fs1, test_fs2, test_fs3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_dow', 'q_hour', 'a_dow', 'a_hour', 'timediff_a-q', 'q_len', 'a_len',\n",
       "       'q_count_words', 'a_count_words', 'q_count_unq_words',\n",
       "       'a_count_unq_words', 'a_dow_min', 'a_dow_max', 'a_dow_max-min',\n",
       "       'a_dow_mean', 'a_dow_std', 'a_dow_nunique', 'a_hour_min', 'a_hour_max',\n",
       "       'a_hour_max-min', 'a_hour_mean', 'a_hour_std', 'a_hour_nunique',\n",
       "       'timediff_a-q_min', 'timediff_a-q_max', 'timediff_a-q_max-min',\n",
       "       'timediff_a-q_mean', 'timediff_a-q_std', 'timediff_a-q_nunique',\n",
       "       'a_len_min', 'a_len_max', 'a_len_max-min', 'a_len_mean', 'a_len_std',\n",
       "       'a_len_nunique', 'a_count_words_min', 'a_count_words_max',\n",
       "       'a_count_words_max-min', 'a_count_words_mean', 'a_count_words_std',\n",
       "       'a_count_words_nunique', 'a_count_unq_words_min',\n",
       "       'a_count_unq_words_max', 'a_count_unq_words_max-min',\n",
       "       'a_count_unq_words_mean', 'a_count_unq_words_std',\n",
       "       'a_count_unq_words_nunique', 'qlenchar', 'qlenword', 'alenchar',\n",
       "       'alenword', 'difflenchar', 'difflenword', 'divlenchar', 'divlenword',\n",
       "       'idivlenchar', 'idivlenword', 'subreddit_le', 'question_score_l1p',\n",
       "       'qboldwords', 'aboldwords', 'acount', 'qEMO0', 'aEMO0', 'qEMO1',\n",
       "       'aEMO1', 'qEMO2', 'aEMO2', 'qEMO3', 'aEMO3', 'qEMO4', 'aEMO4', 'qEMO5',\n",
       "       'aEMO5', 'qEMO6', 'aEMO6', 'qEMO7', 'aEMO7', 'qEMO8', 'aEMO8', 'qEMO9',\n",
       "       'aEMO9', 'qEMO10', 'aEMO10', 'qEMO11', 'aEMO11', 'qEMO12', 'aEMO12',\n",
       "       'qEMO13', 'aEMO13', 'qEMO14', 'aEMO14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fs.fillna(value=0, inplace=True)\n",
    "test_fs.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852885, 92)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()\n",
    "train_num_feats_value=mms.fit_transform(train_fs)\n",
    "test_num_feats_value=mms.transform(test_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and perform text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv', sep='\\t')\n",
    "test=pd.read_csv('../input/test.csv', sep='\\t')\n",
    "\n",
    "train['question_dt']=pd.to_datetime(train['question_utc'], unit='s')\n",
    "test['question_dt']=pd.to_datetime(test['question_utc'], unit='s')\n",
    "train['answer_dt']=pd.to_datetime(train['answer_utc'], unit='s')\n",
    "test['answer_dt']=pd.to_datetime(test['answer_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean question_text] done in 27 s\n"
     ]
    }
   ],
   "source": [
    "reload(kd_utils)\n",
    "with kd_utils.timer('clean question_text'):\n",
    "    train['question_text']=kd_utils.multi_apply_series(train, feature='question_text', \n",
    "                                                          func=kd_utils.preproc_pipeline, n_jobs=4)\n",
    "    test['question_text']=kd_utils.multi_apply_series(test, feature='question_text', \n",
    "                                                          func=kd_utils.preproc_pipeline, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean answer_text] done in 23 s\n"
     ]
    }
   ],
   "source": [
    "reload(kd_utils)\n",
    "with kd_utils.timer('clean answer_text'):\n",
    "    train['answer_text']=kd_utils.multi_apply_series(train, feature='answer_text', \n",
    "                                                          func=kd_utils.preproc_pipeline, n_jobs=4)\n",
    "    test['answer_text']=kd_utils.multi_apply_series(test, feature='answer_text', \n",
    "                                                          func=kd_utils.preproc_pipeline, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest=train.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "max_features = 200000\n",
    "max_len = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fitting tokenizer...\n",
      "   Transforming text to sequences...\n",
      "[Transforming text data to sequences...] done in 131 s\n"
     ]
    }
   ],
   "source": [
    "with kd_utils.timer(\"Transforming text data to sequences...\"):\n",
    "    raw_text = np.hstack([traintest['question_text'].str.lower(), traintest['answer_text'].str.lower()])\n",
    "    print(\"   Fitting tokenizer...\")\n",
    "    tok_raw = Tokenizer()\n",
    "    tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "    print(\"   Transforming text to sequences...\")\n",
    "    traintest['seq_qt'] = tok_raw.texts_to_sequences(traintest['question_text'].str.lower())\n",
    "    traintest['seq_at'] = tok_raw.texts_to_sequences(traintest['answer_text'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kd_utils.pickle_data('../feature_data/tok_raw.pkl',tok_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [104, 25, 4677, 226, 7905, 678, 4, 162, 383, 33, 6, 92, 22, 162, 694, 35, 2, 288, 6, 61, 1, 991, 9, 911, 120, 77, 19, 1, 69, 155, 4, 60, 47, 455, 288, 116, 7, 7748, 2, 35, 57]\n",
       "1    [104, 25, 4677, 226, 7905, 678, 4, 162, 383, 33, 6, 92, 22, 162, 694, 35, 2, 288, 6, 61, 1, 991, 9, 911, 120, 77, 19, 1, 69, 155, 4, 60, 47, 455, 288, 116, 7, 7748, 2, 35, 57]\n",
       "2    [104, 25, 4677, 226, 7905, 678, 4, 162, 383, 33, 6, 92, 22, 162, 694, 35, 2, 288, 6, 61, 1, 991, 9, 911, 120, 77, 19, 1, 69, 155, 4, 60, 47, 455, 288, 116, 7, 7748, 2, 35, 57]\n",
       "3    [104, 25, 4677, 226, 7905, 678, 4, 162, 383, 33, 6, 92, 22, 162, 694, 35, 2, 288, 6, 61, 1, 991, 9, 911, 120, 77, 19, 1, 69, 155, 4, 60, 47, 455, 288, 116, 7, 7748, 2, 35, 57]\n",
       "4    [104, 25, 4677, 226, 7905, 678, 4, 162, 383, 33, 6, 92, 22, 162, 694, 35, 2, 288, 6, 61, 1, 991, 9, 911, 120, 77, 19, 1, 69, 155, 4, 60, 47, 455, 288, 116, 7, 7748, 2, 35, 57]\n",
       "Name: seq_qt, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['seq_qt'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=traintest[0:len(train)]\n",
    "test=traintest[len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model=kd_utils.load_data('../../common_data/fast_text/fasttext_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 11482\n"
     ]
    }
   ],
   "source": [
    "word_index = tok_raw.word_index\n",
    "nb_words = min(max_features, len(word_index))+1\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in fasttext_model.wv.vocab:\n",
    "        embedding_vector = fasttext_model.wv.word_vec(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        try:\n",
    "            embedding_matrix[i]=fasttext_model.wv.word_vec(word)\n",
    "#             pass\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852885, 92)\n",
      "(663082, 92)\n"
     ]
    }
   ],
   "source": [
    "print(train_num_feats_value.shape)\n",
    "print(test_num_feats_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_data(df, values=None):\n",
    "    X = {\n",
    "        'qt': pad_sequences(df.seq_qt, maxlen=max_len),\n",
    "        'at': pad_sequences(df.seq_at, maxlen=max_len),\n",
    "#         'brand_name': np.array(df.brand_name),\n",
    "#         'category_name': pad_sequences(df.seq_category_name, maxlen=MAX_CATEGORY_SEQ),\n",
    "#         'item_condition': np.array(df.item_condition_id),\n",
    "        'num_vars': values\n",
    "#         'num_vars': np.array(df[['shipping', 'sgd_l2_norm','sgd_l1_norm','sgd_l1_l2_norm']]),\n",
    "    }\n",
    "    return X\n",
    "\n",
    "# train = full_df[:n_trains]\n",
    "# dev = full_df[n_trains:n_trains+n_devs]\n",
    "# test = full_df[n_trains+n_devs:]\n",
    "\n",
    "X_train = get_keras_data(train, values=train_num_feats_value)\n",
    "X_test = get_keras_data(test, values=test_num_feats_value)\n",
    "\n",
    "# num_feats_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.log1p(train['answer_score'])\n",
    "# Y_train=train['answer_score'].values[trn_id]\n",
    "# Y_val=train['answer_score'].values[val_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852885,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "qt (InputLayer)                 (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "at (InputLayer)                 (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 250, 300)     60000300    qt[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 250, 300)     60000300    at[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 300)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 300)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 92)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1292)         0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           82752       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          activation_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 120,085,465\n",
      "Trainable params: 84,865\n",
      "Non-trainable params: 120,000,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rmsle_K(y, y0):\n",
    "    return K.sqrt(K.mean(K.square(tf.log1p(y) - tf.log1p(y0))))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred), axis=-1)) \n",
    "\n",
    "def build_model(lr=0.001, decay=0.0):    \n",
    "    \n",
    "    # Inputs\n",
    "    inp_qt = Input(shape=[X_train[\"qt\"].shape[1]], name=\"qt\")\n",
    "    inp_at = Input(shape=[X_train[\"at\"].shape[1]], name=\"at\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    \n",
    "    # Embeddings layers\n",
    "    qt = Embedding(nb_words, embed_size, weights = [embedding_matrix], trainable = False)(inp_qt)\n",
    "    at = Embedding(nb_words, embed_size, weights = [embedding_matrix], trainable = False)(inp_at)\n",
    "\n",
    "#     qt = SpatialDropout1D(0.2)(qt)\n",
    "#     at = SpatialDropout1D(0.2)(at)\n",
    "#     # rnn layers\n",
    "#     qt = Bidirectional(CuDNNGRU(128, return_sequences = True))(qt)\n",
    "#     at = Bidirectional(CuDNNGRU(128, return_sequences = True))(at)\n",
    "    \n",
    "    qt_avg=GlobalAveragePooling1D()(qt)\n",
    "    at_avg=GlobalAveragePooling1D()(at)\n",
    "    \n",
    "    qt_mean=GlobalMaxPooling1D()(qt)\n",
    "    at_mean=GlobalMaxPooling1D()(at)\n",
    "\n",
    "\n",
    "    # main layers\n",
    "    main_l = concatenate([qt_avg, qt_mean, at_avg, at_mean, num_vars])\n",
    "\n",
    "    main_l = Dense(64)(main_l)\n",
    "#     main_l = BatchNormalization()(main_l)\n",
    "#     main_l = Dropout(0.3)(main_l)\n",
    "    \n",
    "    main_l = Dense(32)(main_l)\n",
    "#     main_l = BatchNormalization()(main_l)\n",
    "#     main_l = Dropout(0.3)(main_l)\n",
    "#     main_l = Dense(32)(main_l)\n",
    "#     main_l = Activation('elu')(main_l)\n",
    "    \n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "\n",
    "    model = Model([inp_qt, inp_at, num_vars], output)\n",
    "\n",
    "    optimizer = Adam(lr=lr, decay=decay, clipvalue=0.5)\n",
    "#     clipnorm=0.1\n",
    "#     model.compile(loss=root_mean_squared_error, optimizer = SGD(lr=0.001, momentum=0.9))\n",
    "    model.compile(loss=\"mse\", optimizer = optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852885, 250)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['qt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.7192\n",
      "[epoch 1] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5914\n",
      "[epoch 2] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5642\n",
      "[epoch 3] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5504\n",
      "[epoch 4] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 23us/step - loss: 0.5413\n",
      "[epoch 5] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 23us/step - loss: 0.5354\n",
      "[epoch 6] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5295\n",
      "[epoch 7] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5258\n",
      "[epoch 8] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5230\n",
      "[epoch 9] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 20s 23us/step - loss: 0.5197\n",
      "[epoch 10] done in 20 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 23us/step - loss: 0.5177\n",
      "[epoch 11] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 23us/step - loss: 0.5160\n",
      "[epoch 12] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5143\n",
      "[epoch 13] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5128\n",
      "[epoch 14] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5116\n",
      "[epoch 15] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5105\n",
      "[epoch 16] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5092\n",
      "[epoch 17] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5081\n",
      "[epoch 18] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5075\n",
      "[epoch 19] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5067\n",
      "[epoch 20] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5061\n",
      "[epoch 21] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5051\n",
      "[epoch 22] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5046\n",
      "[epoch 23] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5037\n",
      "[epoch 24] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5035\n",
      "[epoch 25] done in 19 s\n",
      "Epoch 1/1\n",
      "852885/852885 [==============================] - 19s 22us/step - loss: 0.5030\n",
      "[epoch 26] done in 19 s\n",
      "Epoch 1/1\n",
      "663040/852885 [======================>.......] - ETA: 4s - loss: 0.5015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8237571240a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mkd_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch {i + 1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_init\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yifan/anaconda3/envs/dragons_beta/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_init = 1e-3\n",
    "cv_score = 100\n",
    "pred_valid_best = None\n",
    "best_model = None\n",
    "batch_size = 128\n",
    "# early_stopping_count = 0\n",
    "# patience = 5\n",
    "\n",
    "for i in range(60):\n",
    "#     if i < 4:\n",
    "#         batch_size = 2**(6 + i)\n",
    "    with kd_utils.timer(f'epoch {i + 1}'):\n",
    "        ks.backend.set_value(model.optimizer.lr, lr_init/(i+1))\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test, batch_size=1024)\n",
    "pred=np.expm1(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv('../input/sample_submission.csv')\n",
    "sub['answer_score']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8807, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sub.loc[sub['answer_score']<1, :].shape)\n",
    "sub.loc[sub['answer_score']<1, 'answer_score']=1\n",
    "print(sub.loc[sub['answer_score']<1, :].shape)\n",
    "\n",
    "leaks = pd.read_csv(\"../input/leaked_records.csv\").rename(columns={\"answer_score\": \"leak\"})\n",
    "sub = pd.merge(sub, leaks, on=\"id\", how=\"left\")\n",
    "sub.loc[~sub[\"leak\"].isnull(), \"answer_score\"] = sub.loc[~sub[\"leak\"].isnull(), \"leak\"]\n",
    "\n",
    "now=datetime.datetime.now()\n",
    "now=str(now.strftime('%Y-%m-%d-%H-%M'))\n",
    "\n",
    "file='../temp_submissions/yifan_sub_' + now + '.csv.gz'\n",
    "sub[['id','answer_score']].to_csv(file, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
